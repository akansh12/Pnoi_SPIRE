{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_gen(sound_name, mfcc_json_loc,save_loc):\n",
    "    dataframe = pd.DataFrame()\n",
    "    for i in tqdm(os.listdir(mfcc_json_loc)):\n",
    "        with open(mfcc_json_loc+i) as f:\n",
    "            data = json.load(f)\n",
    "        j = len(data[sound_name])\n",
    "        for k in range(0,j):\n",
    "            for l in range(0,len(data[sound_name][k])):\n",
    "                feature = np.array(data[sound_name][k][l])\n",
    "                mean = np.mean(feature,axis=0) \n",
    "                mean = mean.reshape(1,len(mean))\n",
    "                mode = stats.mode(feature,axis = 0)[0]\n",
    "                median = np.median(feature, axis=0)\n",
    "                median = median.reshape(1,len(median))\n",
    "\n",
    "                variance = np.var(feature, axis=0)\n",
    "                variance = variance.reshape(1,len(variance))\n",
    "\n",
    "                sd = np.std(feature,axis = 0)\n",
    "                sd = sd.reshape(1,len(sd))\n",
    "\n",
    "                rms = np.sqrt(np.mean(np.square(feature),axis=0))\n",
    "                rms = rms.reshape(1,len(rms))\n",
    "\n",
    "                big = np.concatenate((mean,median,mode,variance,sd,rms),axis = 0)\n",
    "                feature_vector = big.reshape(1,big.shape[0]*big.shape[1])\n",
    "                if i.find(\"Asthma\") != -1:\n",
    "                    feature_vector = np.append(feature_vector,1)\n",
    "                    feature_vector = np.append(feature_vector,i).reshape(1,74)\n",
    "                else:\n",
    "                    feature_vector = np.append(feature_vector,0)\n",
    "                    feature_vector = np.append(feature_vector,i).reshape(1,74)\n",
    "\n",
    "                dataframe = dataframe.append(pd.DataFrame(feature_vector))\n",
    "                dataframe.to_csv(save_loc+sound_name+\".csv\", index = False)\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [11:58<00:00, 27.85s/it]\n"
     ]
    }
   ],
   "source": [
    "csv_gen(\"eko\", \"./MFCC_calculated_16k_mic/\", save_loc=\"./mfcc_csv_16k_mic/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [11:14<00:00, 25.37s/it]\n"
     ]
    }
   ],
   "source": [
    "csv_gen(\"mic\", \"./MFCC_calculated_16k_mic/\", save_loc=\"./mfcc_csv_16k_mic/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CMN MIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat('MFCC_mic.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mic\n",
    "Mean_mic = np.mean(mat['big'][1:], axis=0).reshape(1,12)\n",
    "\n",
    "STD_mic = np.std(mat['big'][1:], axis=0).reshape(1,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_gen(sound_name, mfcc_json_loc,save_loc):\n",
    "    dataframe = pd.DataFrame()\n",
    "    for i in tqdm(os.listdir(mfcc_json_loc)):\n",
    "        with open(mfcc_json_loc+i) as f:\n",
    "            data = json.load(f)\n",
    "        j = len(data[sound_name])\n",
    "        for k in range(0,j):\n",
    "            for l in range(0,len(data[sound_name][k])):\n",
    "                feature = np.array(data[sound_name][k][l])\n",
    "                ### CMN\n",
    "                feature = (np.array(data[sound_name][k][l])-Mean)/STD            \n",
    "                                \n",
    "                ##### \n",
    "                mean = np.mean(feature,axis=0) \n",
    "                mean = mean.reshape(1,len(mean))\n",
    "                mode = stats.mode(feature,axis = 0)[0]\n",
    "                median = np.median(feature, axis=0)\n",
    "                median = median.reshape(1,len(median))\n",
    "\n",
    "                variance = np.var(feature, axis=0)\n",
    "                variance = variance.reshape(1,len(variance))\n",
    "\n",
    "                sd = np.std(feature,axis = 0)\n",
    "                sd = sd.reshape(1,len(sd))\n",
    "\n",
    "                rms = np.sqrt(np.mean(np.square(feature),axis=0))\n",
    "                rms = rms.reshape(1,len(rms))\n",
    "\n",
    "                big = np.concatenate((mean,median,mode,variance,sd,rms),axis = 0)\n",
    "                feature_vector = big.reshape(1,big.shape[0]*big.shape[1])\n",
    "                if i.find(\"Asthma\") != -1:\n",
    "                    feature_vector = np.append(feature_vector,1)\n",
    "                    feature_vector = np.append(feature_vector,i).reshape(1,74)\n",
    "                else:\n",
    "                    feature_vector = np.append(feature_vector,0)\n",
    "                    feature_vector = np.append(feature_vector,i).reshape(1,74)\n",
    "\n",
    "                dataframe = dataframe.append(pd.DataFrame(feature_vector))\n",
    "                dataframe.to_csv(save_loc+sound_name+\".csv\", index = False)\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [11:53<00:00, 27.96s/it]\n"
     ]
    }
   ],
   "source": [
    "csv_gen(\"mic\", \"./MFCC_calculated_16k_mic/\", save_loc=\"./mfcc_csv_16k_mic/CMN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EKO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat('MFCC_eko.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eko\n",
    "Mean_eko = np.mean(mat['big'][1:], axis=0).reshape(1,12)\n",
    "\n",
    "STD_eko = np.std(mat['big'][1:], axis=0).reshape(1,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [07:29<00:00, 17.35s/it]\n"
     ]
    }
   ],
   "source": [
    "csv_gen(\"eko\", \"./MFCC_calculated_16k_mic/\", save_loc=\"./mfcc_csv_16k_mic/CMN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12 X 53 X 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with CMN\n",
    "def csv_gen(sound_name, mfcc_json_loc,save_loc):\n",
    "    dataframe = pd.DataFrame()\n",
    "    for i in tqdm(os.listdir(mfcc_json_loc)):\n",
    "        with open(mfcc_json_loc+i) as f:\n",
    "            data = json.load(f)\n",
    "        j = len(data[sound_name])\n",
    "        for k in range(0,j):\n",
    "            try:\n",
    "                l = 2\n",
    "                feature = np.array(data[sound_name][k][l])\n",
    "                ### CMN\n",
    "#                 feature = (np.array(data[sound_name][k][l])-Mean)/STD                           \n",
    "                ##### \n",
    "            except:\n",
    "                l = 0\n",
    "                feature = np.array(data[sound_name][k][l])\n",
    "                ### CMN\n",
    "#                 feature = (np.array(data[sound_name][k][l])-Mean)/STD                        \n",
    "                ##### \n",
    "            mean = np.mean(feature,axis=0) \n",
    "            mean = mean.reshape(1,len(mean))\n",
    "            mode = stats.mode(feature,axis = 0)[0]\n",
    "            median = np.median(feature, axis=0)\n",
    "            median = median.reshape(1,len(median))\n",
    "\n",
    "            variance = np.var(feature, axis=0)\n",
    "            variance = variance.reshape(1,len(variance))\n",
    "\n",
    "            sd = np.std(feature,axis = 0)\n",
    "            sd = sd.reshape(1,len(sd))\n",
    "\n",
    "            rms = np.sqrt(np.mean(np.square(feature),axis=0))\n",
    "            rms = rms.reshape(1,len(rms))\n",
    "\n",
    "            big = np.concatenate((mean,median,mode,variance,sd,rms),axis = 0)\n",
    "            feature_vector = big.reshape(1,big.shape[0]*big.shape[1])\n",
    "            if i.find(\"Asthma\") != -1:\n",
    "                feature_vector = np.append(feature_vector,1)\n",
    "                feature_vector = np.append(feature_vector,i).reshape(1,74)\n",
    "            else:\n",
    "                feature_vector = np.append(feature_vector,0)\n",
    "                feature_vector = np.append(feature_vector,i).reshape(1,74)\n",
    "\n",
    "            dataframe = dataframe.append(pd.DataFrame(feature_vector))\n",
    "            dataframe.to_csv(save_loc+sound_name+\".csv\", index = False)\n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:32<00:00,  1.25it/s]\n"
     ]
    }
   ],
   "source": [
    "csv_gen(\"mic\", \"./MFCC_calculated_16k_mic/\", save_loc=\"./mfcc_csv_16k_mic/withCMN-12X53\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:18<00:00,  2.31it/s]\n"
     ]
    }
   ],
   "source": [
    "csv_gen(\"eko\", \"./MFCC_calculated_16k_mic/\", save_loc=\"./mfcc_csv_16k_mic/withCMN-12X53\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:17<00:00,  2.25it/s]\n"
     ]
    }
   ],
   "source": [
    "csv_gen(\"eko\", \"./MFCC_calculated_16k_mic/\", save_loc=\"./mfcc_csv_16k_mic/withoutCMN-12X53\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location Sensitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_json_loc = './MFCC_resampled_location_sensitive/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_loc = \"./mfcc_csv_16k_mic/withoutCMN(all)\"\n",
    "# save_loc = \"./mfcc_csv_16k_mic/withCMN(all)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/53 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 1/53 [00:02<02:21,  2.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 2/53 [00:07<02:49,  3.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 3/53 [00:10<02:34,  3.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 4/53 [00:13<02:40,  3.28s/it]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 5/53 [00:15<02:21,  2.94s/it]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█▏        | 6/53 [00:18<02:14,  2.87s/it]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 7/53 [00:20<02:04,  2.72s/it]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 8/53 [00:24<02:16,  3.03s/it]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 9/53 [00:27<02:07,  2.89s/it]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 10/53 [00:30<02:06,  2.94s/it]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 11/53 [00:33<02:05,  2.98s/it]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 12/53 [00:39<02:46,  4.05s/it]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 13/53 [00:43<02:34,  3.86s/it]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 14/53 [00:46<02:21,  3.63s/it]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 15/53 [00:49<02:12,  3.49s/it]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 16/53 [00:55<02:34,  4.18s/it]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 17/53 [01:00<02:39,  4.42s/it]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 18/53 [01:04<02:30,  4.30s/it]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 19/53 [01:12<03:06,  5.49s/it]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 20/53 [01:16<02:47,  5.07s/it]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 21/53 [01:20<02:31,  4.72s/it]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 22/53 [01:26<02:35,  5.02s/it]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 23/53 [01:32<02:39,  5.32s/it]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 24/53 [01:35<02:10,  4.50s/it]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 25/53 [01:42<02:28,  5.32s/it]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 26/53 [01:49<02:37,  5.83s/it]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 27/53 [01:55<02:32,  5.85s/it]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 28/53 [01:59<02:12,  5.28s/it]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 29/53 [02:05<02:11,  5.48s/it]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 30/53 [02:09<01:59,  5.18s/it]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 31/53 [02:14<01:54,  5.19s/it]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 32/53 [02:21<02:01,  5.79s/it]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 33/53 [02:26<01:50,  5.53s/it]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 34/53 [02:30<01:34,  4.98s/it]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 35/53 [02:34<01:23,  4.64s/it]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 36/53 [02:40<01:28,  5.18s/it]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 37/53 [02:47<01:31,  5.71s/it]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 38/53 [02:51<01:14,  4.99s/it]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▎  | 39/53 [03:00<01:28,  6.33s/it]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 40/53 [03:06<01:20,  6.18s/it]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 41/53 [03:08<00:59,  4.92s/it]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 42/53 [03:10<00:44,  4.06s/it]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 43/53 [03:16<00:45,  4.56s/it]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 44/53 [03:22<00:46,  5.19s/it]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▍ | 45/53 [03:30<00:47,  5.91s/it]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 46/53 [03:36<00:41,  5.90s/it]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▊ | 47/53 [03:41<00:34,  5.82s/it]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 48/53 [03:50<00:33,  6.65s/it]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 49/53 [03:54<00:23,  5.85s/it]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 50/53 [04:02<00:19,  6.40s/it]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 51/53 [04:14<00:16,  8.05s/it]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 52/53 [04:24<00:08,  8.83s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 53/53 [04:31<00:00,  8.21s/it]\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "# sound_name = 'mic'\n",
    "sound_name = 'eko'\n",
    "Mean = Mean_eko # Mean\n",
    "STD = STD_eko\n",
    "dataframe_B_R_T_DPB = pd.DataFrame()\n",
    "dataframe_B_R_D_DPB = pd.DataFrame()\n",
    "dataframe_B_L_D_DPB = pd.DataFrame()\n",
    "dataframe_B_L_T_DPB = pd.DataFrame()\n",
    "for i in tqdm(os.listdir(mfcc_json_loc)):\n",
    "    with open(mfcc_json_loc+i) as f:\n",
    "        data = json.load(f)\n",
    "#     j = len(data[sound_name])\n",
    "    for k in data['mic'].keys():\n",
    "        for l in range(0,len(data[sound_name][k])):\n",
    "            for m in range(0,len(data[sound_name][k][l])):\n",
    "                feature = np.array(data[sound_name][k][l][m])\n",
    "                ### CMN\n",
    "#                 feature = (np.array(data[sound_name][k][l][m])-Mean)/STD            \n",
    "\n",
    "                ##### \n",
    "                mean = np.mean(feature,axis=0) \n",
    "                mean = mean.reshape(1,len(mean))\n",
    "                mode = stats.mode(feature,axis = 0)[0]\n",
    "                median = np.median(feature, axis=0)\n",
    "                median = median.reshape(1,len(median))\n",
    "\n",
    "                variance = np.var(feature, axis=0)\n",
    "                variance = variance.reshape(1,len(variance))\n",
    "\n",
    "                sd = np.std(feature,axis = 0)\n",
    "                sd = sd.reshape(1,len(sd))\n",
    "\n",
    "                rms = np.sqrt(np.mean(np.square(feature),axis=0))\n",
    "                rms = rms.reshape(1,len(rms))\n",
    "\n",
    "                big = np.concatenate((mean,median,mode,variance,sd,rms),axis = 0)\n",
    "                feature_vector = big.reshape(1,big.shape[0]*big.shape[1])\n",
    "                if i.find(\"Asthma\") != -1:\n",
    "                    feature_vector = np.append(feature_vector,1)\n",
    "                    feature_vector = np.append(feature_vector,i).reshape(1,74)\n",
    "                else:\n",
    "                    feature_vector = np.append(feature_vector,0)\n",
    "                    feature_vector = np.append(feature_vector,i).reshape(1,74)\n",
    "                \n",
    "                if k == 'B_R_T_DPB':                    \n",
    "                    dataframe_B_R_T_DPB = dataframe_B_R_T_DPB.append(pd.DataFrame(feature_vector))\n",
    "                    dataframe_B_R_T_DPB.to_csv(save_loc+sound_name+k+\".csv\", index = False)\n",
    "                if k == 'B_R_D_DPB':                    \n",
    "                    dataframe_B_R_D_DPB = dataframe_B_R_D_DPB.append(pd.DataFrame(feature_vector))\n",
    "                    dataframe_B_R_D_DPB.to_csv(save_loc+sound_name+k+\".csv\", index = False)\n",
    "                if k == 'B_L_D_DPB':                    \n",
    "                    dataframe_B_L_D_DPB = dataframe_B_L_D_DPB.append(pd.DataFrame(feature_vector))\n",
    "                    dataframe_B_L_D_DPB.to_csv(save_loc+sound_name+k+\".csv\", index = False)\n",
    "                if k == 'B_L_T_DPB':                    \n",
    "                    dataframe_B_L_T_DPB = dataframe_B_L_T_DPB.append(pd.DataFrame(feature_vector))\n",
    "                    dataframe_B_L_T_DPB.to_csv(save_loc+sound_name+k+\".csv\", index = False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./mfcc_csv_16k_mic/withCMN(all)'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_loc=\"./mfcc_csv_16k_mic/withoutCMN-12X53\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/53 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 1/53 [00:01<01:13,  1.41s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 2/53 [00:03<01:16,  1.51s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 3/53 [00:05<01:26,  1.73s/it]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 4/53 [00:08<01:44,  2.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 5/53 [00:10<01:41,  2.11s/it]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█▏        | 6/53 [00:12<01:42,  2.18s/it]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 7/53 [00:14<01:35,  2.09s/it]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 8/53 [00:17<01:49,  2.44s/it]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 9/53 [00:20<01:46,  2.42s/it]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 10/53 [00:22<01:43,  2.40s/it]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 11/53 [00:25<01:51,  2.66s/it]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 12/53 [00:31<02:28,  3.63s/it]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 13/53 [00:34<02:11,  3.30s/it]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 14/53 [00:36<01:59,  3.06s/it]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 15/53 [00:39<01:50,  2.90s/it]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 16/53 [00:44<02:11,  3.57s/it]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 17/53 [00:49<02:19,  3.87s/it]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 18/53 [00:52<02:05,  3.57s/it]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 19/53 [00:59<02:38,  4.67s/it]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 20/53 [01:03<02:28,  4.49s/it]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 21/53 [01:07<02:18,  4.33s/it]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 22/53 [01:15<02:48,  5.44s/it]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 23/53 [01:20<02:40,  5.35s/it]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 24/53 [01:22<02:05,  4.32s/it]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 25/53 [01:28<02:13,  4.78s/it]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 26/53 [01:35<02:25,  5.40s/it]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 27/53 [01:40<02:23,  5.53s/it]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 28/53 [01:44<02:06,  5.08s/it]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 29/53 [01:49<01:58,  4.92s/it]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 30/53 [01:53<01:43,  4.51s/it]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 31/53 [01:57<01:38,  4.50s/it]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 32/53 [02:05<01:57,  5.59s/it]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 33/53 [02:09<01:42,  5.12s/it]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 34/53 [02:13<01:27,  4.62s/it]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 35/53 [02:17<01:20,  4.45s/it]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 36/53 [02:23<01:27,  5.16s/it]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 37/53 [02:31<01:33,  5.84s/it]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 38/53 [02:34<01:15,  5.04s/it]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▎  | 39/53 [02:44<01:29,  6.39s/it]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 40/53 [02:51<01:26,  6.65s/it]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 41/53 [02:54<01:06,  5.52s/it]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 42/53 [02:56<00:50,  4.59s/it]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 43/53 [03:03<00:53,  5.31s/it]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 44/53 [03:13<00:59,  6.57s/it]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▍ | 45/53 [03:20<00:55,  6.89s/it]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 46/53 [03:26<00:45,  6.54s/it]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▊ | 47/53 [03:32<00:38,  6.42s/it]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 48/53 [03:40<00:34,  6.88s/it]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 49/53 [03:44<00:23,  5.97s/it]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 50/53 [03:53<00:20,  6.85s/it]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 51/53 [04:05<00:16,  8.48s/it]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 52/53 [04:16<00:09,  9.17s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 53/53 [04:23<00:00,  8.59s/it]\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "# sound_name = 'mic'\n",
    "sound_name = 'eko'\n",
    "# Mean = Mean_eko # Mean\n",
    "# STD = STD_eko\n",
    "dataframe_B_R_T_DPB = pd.DataFrame()\n",
    "dataframe_B_R_D_DPB = pd.DataFrame()\n",
    "dataframe_B_L_D_DPB = pd.DataFrame()\n",
    "dataframe_B_L_T_DPB = pd.DataFrame()\n",
    "for i in tqdm(os.listdir(mfcc_json_loc)):\n",
    "    with open(mfcc_json_loc+i) as f:\n",
    "        data = json.load(f)\n",
    "#     j = len(data[sound_name])\n",
    "    for k in data['mic'].keys():\n",
    "        for l in range(0,len(data[sound_name][k])):\n",
    "            for m in range(0,len(data[sound_name][k][l])):\n",
    "                feature = np.array(data[sound_name][k][l][m])\n",
    "                try:\n",
    "                    m = 2\n",
    "                    feature = np.array(data[sound_name][k][l][m])\n",
    "                    ### CMN\n",
    "    #                 feature = (np.array(data[sound_name][k][l])-Mean)/STD                           \n",
    "                    ##### \n",
    "                except:\n",
    "                    m = 0\n",
    "                    feature = np.array(data[sound_name][k][l][m])\n",
    "                    ### CMN\n",
    "    #                 feature = (np.array(data[sound_name][k][l])-Mean)/STD                        \n",
    "                    ##### \n",
    "                mean = np.mean(feature,axis=0) \n",
    "                mean = mean.reshape(1,len(mean))\n",
    "                mode = stats.mode(feature,axis = 0)[0]\n",
    "                median = np.median(feature, axis=0)\n",
    "                median = median.reshape(1,len(median))\n",
    "\n",
    "                variance = np.var(feature, axis=0)\n",
    "                variance = variance.reshape(1,len(variance))\n",
    "\n",
    "                sd = np.std(feature,axis = 0)\n",
    "                sd = sd.reshape(1,len(sd))\n",
    "\n",
    "                rms = np.sqrt(np.mean(np.square(feature),axis=0))\n",
    "                rms = rms.reshape(1,len(rms))\n",
    "\n",
    "                big = np.concatenate((mean,median,mode,variance,sd,rms),axis = 0)\n",
    "                feature_vector = big.reshape(1,big.shape[0]*big.shape[1])\n",
    "                if i.find(\"Asthma\") != -1:\n",
    "                    feature_vector = np.append(feature_vector,1)\n",
    "                    feature_vector = np.append(feature_vector,i).reshape(1,74)\n",
    "                else:\n",
    "                    feature_vector = np.append(feature_vector,0)\n",
    "                    feature_vector = np.append(feature_vector,i).reshape(1,74)\n",
    "                \n",
    "                if k == 'B_R_T_DPB':                    \n",
    "                    dataframe_B_R_T_DPB = dataframe_B_R_T_DPB.append(pd.DataFrame(feature_vector))\n",
    "                    dataframe_B_R_T_DPB.to_csv(save_loc+sound_name+k+\".csv\", index = False)\n",
    "                if k == 'B_R_D_DPB':                    \n",
    "                    dataframe_B_R_D_DPB = dataframe_B_R_D_DPB.append(pd.DataFrame(feature_vector))\n",
    "                    dataframe_B_R_D_DPB.to_csv(save_loc+sound_name+k+\".csv\", index = False)\n",
    "                if k == 'B_L_D_DPB':                    \n",
    "                    dataframe_B_L_D_DPB = dataframe_B_L_D_DPB.append(pd.DataFrame(feature_vector))\n",
    "                    dataframe_B_L_D_DPB.to_csv(save_loc+sound_name+k+\".csv\", index = False)\n",
    "                if k == 'B_L_T_DPB':                    \n",
    "                    dataframe_B_L_T_DPB = dataframe_B_L_T_DPB.append(pd.DataFrame(feature_vector))\n",
    "                    dataframe_B_L_T_DPB.to_csv(save_loc+sound_name+k+\".csv\", index = False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_loc=\"./mfcc_csv_16k_mic/withCMN-12X53\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/53 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 1/53 [00:01<01:43,  2.00s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 2/53 [00:04<01:44,  2.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 3/53 [00:07<01:56,  2.33s/it]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 4/53 [00:11<02:18,  2.82s/it]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 5/53 [00:13<02:12,  2.76s/it]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█▏        | 6/53 [00:17<02:18,  2.94s/it]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 7/53 [00:19<02:02,  2.66s/it]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 8/53 [00:23<02:28,  3.31s/it]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 9/53 [00:26<02:21,  3.22s/it]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 10/53 [00:30<02:18,  3.23s/it]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 11/53 [00:33<02:20,  3.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 12/53 [00:40<02:53,  4.24s/it]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 13/53 [00:43<02:36,  3.91s/it]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 14/53 [00:45<02:13,  3.42s/it]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 15/53 [00:48<02:05,  3.30s/it]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 16/53 [00:53<02:19,  3.76s/it]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 17/53 [00:57<02:20,  3.91s/it]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 18/53 [01:00<02:09,  3.71s/it]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 19/53 [01:08<02:40,  4.72s/it]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 20/53 [01:11<02:21,  4.30s/it]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 21/53 [01:14<02:06,  3.96s/it]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 22/53 [01:20<02:24,  4.67s/it]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 23/53 [01:25<02:24,  4.82s/it]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 24/53 [01:28<01:55,  3.99s/it]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 25/53 [01:33<02:07,  4.54s/it]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 26/53 [01:40<02:19,  5.18s/it]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 27/53 [01:45<02:13,  5.14s/it]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 28/53 [01:49<01:55,  4.63s/it]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 29/53 [01:54<01:58,  4.92s/it]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 30/53 [01:59<01:49,  4.77s/it]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 31/53 [02:03<01:43,  4.71s/it]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 32/53 [02:11<01:59,  5.68s/it]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 33/53 [02:16<01:47,  5.40s/it]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 34/53 [02:19<01:31,  4.80s/it]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 35/53 [02:23<01:22,  4.58s/it]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 36/53 [02:31<01:32,  5.44s/it]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 37/53 [02:39<01:38,  6.18s/it]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 38/53 [02:42<01:20,  5.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▎  | 39/53 [02:54<01:42,  7.29s/it]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 40/53 [03:00<01:29,  6.85s/it]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 41/53 [03:02<01:05,  5.48s/it]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 42/53 [03:04<00:48,  4.38s/it]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 43/53 [03:09<00:46,  4.69s/it]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 44/53 [03:16<00:47,  5.24s/it]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▍ | 45/53 [03:24<00:48,  6.08s/it]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 46/53 [03:29<00:41,  5.90s/it]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▊ | 47/53 [03:35<00:35,  5.92s/it]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 48/53 [03:43<00:32,  6.53s/it]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 49/53 [03:47<00:22,  5.59s/it]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 50/53 [03:53<00:17,  5.85s/it]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 51/53 [04:04<00:14,  7.34s/it]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 52/53 [04:16<00:08,  8.71s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 53/53 [04:22<00:00,  8.08s/it]\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "# sound_name = 'mic'\n",
    "sound_name = 'eko'\n",
    "Mean = Mean_eko # Mean\n",
    "STD = STD_eko\n",
    "dataframe_B_R_T_DPB = pd.DataFrame()\n",
    "dataframe_B_R_D_DPB = pd.DataFrame()\n",
    "dataframe_B_L_D_DPB = pd.DataFrame()\n",
    "dataframe_B_L_T_DPB = pd.DataFrame()\n",
    "for i in tqdm(os.listdir(mfcc_json_loc)):\n",
    "    with open(mfcc_json_loc+i) as f:\n",
    "        data = json.load(f)\n",
    "#     j = len(data[sound_name])\n",
    "    for k in data['mic'].keys():\n",
    "        for l in range(0,len(data[sound_name][k])):\n",
    "            for m in range(0,len(data[sound_name][k][l])):\n",
    "                feature = np.array(data[sound_name][k][l][m])\n",
    "                try:\n",
    "                    m = 2\n",
    "                    feature = np.array(data[sound_name][k][l][m])\n",
    "                    ### CMN\n",
    "                    feature = (np.array(data[sound_name][k][l][m])-Mean)/STD                           \n",
    "                    ##### \n",
    "                except:\n",
    "                    m = 0\n",
    "                    feature = np.array(data[sound_name][k][l][m])\n",
    "                    ### CMN\n",
    "                    feature = (np.array(data[sound_name][k][l][m])-Mean)/STD                        \n",
    "                    ##### \n",
    "                mean = np.mean(feature,axis=0) \n",
    "                mean = mean.reshape(1,len(mean))\n",
    "                mode = stats.mode(feature,axis = 0)[0]\n",
    "                median = np.median(feature, axis=0)\n",
    "                median = median.reshape(1,len(median))\n",
    "\n",
    "                variance = np.var(feature, axis=0)\n",
    "                variance = variance.reshape(1,len(variance))\n",
    "\n",
    "                sd = np.std(feature,axis = 0)\n",
    "                sd = sd.reshape(1,len(sd))\n",
    "\n",
    "                rms = np.sqrt(np.mean(np.square(feature),axis=0))\n",
    "                rms = rms.reshape(1,len(rms))\n",
    "\n",
    "                big = np.concatenate((mean,median,mode,variance,sd,rms),axis = 0)\n",
    "                feature_vector = big.reshape(1,big.shape[0]*big.shape[1])\n",
    "                if i.find(\"Asthma\") != -1:\n",
    "                    feature_vector = np.append(feature_vector,1)\n",
    "                    feature_vector = np.append(feature_vector,i).reshape(1,74)\n",
    "                else:\n",
    "                    feature_vector = np.append(feature_vector,0)\n",
    "                    feature_vector = np.append(feature_vector,i).reshape(1,74)\n",
    "                \n",
    "                if k == 'B_R_T_DPB':                    \n",
    "                    dataframe_B_R_T_DPB = dataframe_B_R_T_DPB.append(pd.DataFrame(feature_vector))\n",
    "                    dataframe_B_R_T_DPB.to_csv(save_loc+sound_name+k+\".csv\", index = False)\n",
    "                if k == 'B_R_D_DPB':                    \n",
    "                    dataframe_B_R_D_DPB = dataframe_B_R_D_DPB.append(pd.DataFrame(feature_vector))\n",
    "                    dataframe_B_R_D_DPB.to_csv(save_loc+sound_name+k+\".csv\", index = False)\n",
    "                if k == 'B_L_D_DPB':                    \n",
    "                    dataframe_B_L_D_DPB = dataframe_B_L_D_DPB.append(pd.DataFrame(feature_vector))\n",
    "                    dataframe_B_L_D_DPB.to_csv(save_loc+sound_name+k+\".csv\", index = False)\n",
    "                if k == 'B_L_T_DPB':                    \n",
    "                    dataframe_B_L_T_DPB = dataframe_B_L_T_DPB.append(pd.DataFrame(feature_vector))\n",
    "                    dataframe_B_L_T_DPB.to_csv(save_loc+sound_name+k+\".csv\", index = False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

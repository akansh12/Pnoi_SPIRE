{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akansh/anaconda3/lib/python3.7/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  '\"sox\" backend is being deprecated. '\n"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json  \n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_eko_to_mic (wav_file_name):\n",
    "    b = k.split('_')\n",
    "    b[1] = 'Mic'\n",
    "    separator = '_'\n",
    "    return separator.join(b)[:-3] +'wav'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MFCC(waveform, sample_rate):\n",
    "    mfcc = torchaudio.compliance.kaldi.mfcc(waveform=waveform,num_ceps = 12,   \n",
    "                                     cepstral_lifter=22, channel=0, \n",
    "                                     dither = 0.0, energy_floor=0.0,\n",
    "                                     frame_length=20, frame_shift=10, \n",
    "                                     high_freq=sample_rate/2,low_freq = 40, num_mel_bins=25, \n",
    "                                     sample_frequency=sample_rate, use_energy=True, vtln_low =60  , vtln_high = 7200, \n",
    "                                     window_type=\"hamming\")\n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_eko (wav_file_name):\n",
    "    b = k.split('_')\n",
    "    b[1] = 'Label'\n",
    "    separator = '_'\n",
    "    return separator.join(b)[:-3] +'txt'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]/home/akansh/anaconda3/lib/python3.7/site-packages/torchaudio/compliance/kaldi.py:574: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n",
      "  fft = torch.rfft(strided_input, 1, normalized=False, onesided=True)\n",
      " 29%|██▊       | 2/7 [00:06<00:16,  3.25s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-a4c3d0896463>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nnotat'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                     \u001b[0msub_wav_mfcc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMFCC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwaveform_mic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0mmic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_wav_mfcc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mic'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-783c233f861d>\u001b[0m in \u001b[0;36mMFCC\u001b[0;34m(waveform, sample_rate)\u001b[0m\n\u001b[1;32m      6\u001b[0m                                      \u001b[0mhigh_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlow_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_mel_bins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                      \u001b[0msample_frequency\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_energy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvtln_low\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m  \u001b[0;34m,\u001b[0m \u001b[0mvtln_high\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m7200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                                      window_type=\"hamming\")\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmfcc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchaudio/compliance/kaldi.py\u001b[0m in \u001b[0;36mmfcc\u001b[0;34m(waveform, blackman_coeff, cepstral_lifter, channel, dither, energy_floor, frame_length, frame_shift, high_freq, htk_compat, low_freq, num_ceps, min_duration, num_mel_bins, preemphasis_coefficient, raw_energy, remove_dc_offset, round_to_power_of_two, sample_frequency, snip_edges, subtract_mean, use_energy, vtln_high, vtln_low, vtln_warp, window_type)\u001b[0m\n\u001b[1;32m    715\u001b[0m                     \u001b[0msample_frequency\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_frequency\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msnip_edges\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msnip_edges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubtract_mean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m                     \u001b[0muse_energy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_energy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_log_fbank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_power\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m                     vtln_high=vtln_high, vtln_low=vtln_low, vtln_warp=vtln_warp, window_type=window_type)\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_energy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchaudio/compliance/kaldi.py\u001b[0m in \u001b[0;36mfbank\u001b[0;34m(waveform, blackman_coeff, channel, dither, energy_floor, frame_length, frame_shift, high_freq, htk_compat, low_freq, min_duration, num_mel_bins, preemphasis_coefficient, raw_energy, remove_dc_offset, round_to_power_of_two, sample_frequency, snip_edges, subtract_mean, use_energy, use_log_fbank, use_power, vtln_high, vtln_low, vtln_warp, window_type)\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;31m# size (num_mel_bins, padded_window_size // 2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m     mel_energies, _ = get_mel_banks(num_mel_bins, padded_window_size, sample_frequency,\n\u001b[0;32m--> 582\u001b[0;31m                                     low_freq, high_freq, vtln_low, vtln_high, vtln_warp)\n\u001b[0m\u001b[1;32m    583\u001b[0m     \u001b[0mmel_energies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmel_energies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchaudio/compliance/kaldi.py\u001b[0m in \u001b[0;36mget_mel_banks\u001b[0;34m(num_bins, window_length_padded, sample_freq, low_freq, high_freq, vtln_low, vtln_high, vtln_warp_factor)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0mbin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_bins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m     \u001b[0mleft_mel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmel_low_freq\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbin\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmel_freq_delta\u001b[0m  \u001b[0;31m# size(num_bins, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m     \u001b[0mcenter_mel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmel_low_freq\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbin\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmel_freq_delta\u001b[0m  \u001b[0;31m# size(num_bins, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0mright_mel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmel_low_freq\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbin\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmel_freq_delta\u001b[0m  \u001b[0;31m# size(num_bins, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "set_loc = \"./Sets/\"\n",
    "data_loc = \"./\"\n",
    "for i in os.listdir(set_loc):\n",
    "    set_full = np.loadtxt(set_loc + i, dtype=str)\n",
    "    for j in tqdm(set_full):\n",
    "        A = {}\n",
    "        eko = []\n",
    "        mic = []\n",
    "        for k in os.listdir(data_loc+j+'/Eko'):\n",
    "            sub_wav_mfcc = []\n",
    "            waveform_eko, sample_rate = torchaudio.load(data_loc+j+'/Eko/'+k)\n",
    "            txt_file = pd.read_csv(data_loc+j+'/labels/'+labels_eko(k), sep=\"\\t\", header = None)\n",
    "            labels = txt_file.iloc[:,2]\n",
    "            start = txt_file.iloc[:,0]\n",
    "            stop = txt_file.iloc[:,1]\n",
    "            for l,m in enumerate(labels):\n",
    "                if m.find('nnotat') != -1:\n",
    "                    sub_wav_mfcc.append(MFCC(waveform_eko[:,int(round(start[l]*sample_rate)):int(round(stop[l]*sample_rate))], sample_rate).numpy().tolist())\n",
    "            eko.append(sub_wav_mfcc)\n",
    "        A['eko']= eko\n",
    "        for k in os.listdir(data_loc+j+'/Mic'):\n",
    "            sub_wav_mfcc = []\n",
    "            waveform_mic, sample_rate = torchaudio.load(data_loc+j+'/Mic/'+k)\n",
    "            txt_file = pd.read_csv(data_loc+j+'/labels/'+labels_eko(k), sep=\"\\t\", header = None)\n",
    "            labels = txt_file.iloc[:,2]\n",
    "            start = txt_file.iloc[:,0]\n",
    "            stop = txt_file.iloc[:,1]\n",
    "            for l,m in enumerate(labels):\n",
    "                if m.find('nnotat') != -1:\n",
    "                    sub_wav_mfcc.append(MFCC(waveform_mic[:,int(round(start[l]*sample_rate)):int(round(stop[l]*sample_rate))], sample_rate).numpy().tolist())\n",
    "            mic.append(sub_wav_mfcc)\n",
    "        A['mic']= mic\n",
    "        with open(\"./\"+j+\".json\", \"w\") as outfile:  \n",
    "            json.dump(A, outfile)\n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SabiaKhatun_Mic_2019_12_13_11_18_02.615_B_L_T_DPB_3.wav'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 144 MFCC(concat eko and Mic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:44<00:00,  6.60s/it]\n",
      "100%|██████████| 8/8 [01:01<00:00,  8.05s/it]\n",
      "100%|██████████| 7/7 [00:46<00:00,  6.94s/it]\n",
      "100%|██████████| 8/8 [00:52<00:00,  6.35s/it]\n",
      "100%|██████████| 8/8 [00:45<00:00,  5.55s/it]\n",
      "100%|██████████| 8/8 [00:44<00:00,  5.54s/it]\n",
      "100%|██████████| 7/7 [00:38<00:00,  5.68s/it]\n"
     ]
    }
   ],
   "source": [
    "set_loc = \"./Sets/\"\n",
    "data_loc = \"./\"\n",
    "for i in os.listdir(set_loc):\n",
    "    set_full = np.loadtxt(set_loc + i, dtype=str)\n",
    "    for j in tqdm(set_full):\n",
    "        A = {}\n",
    "        eko = []\n",
    "        mic = []   \n",
    "        for k in os.listdir(data_loc+j+'/Eko'):\n",
    "            sub_wav_mfcc_eko = []\n",
    "            sub_wav_mfcc_mic = []\n",
    "            waveform_eko, sample_rate = torchaudio.load(data_loc+j+'/Eko/'+k)\n",
    "            waveform_mic, sample_rate_2 = torchaudio.load(data_loc+j+'/Mic/'+labels_eko_to_mic(k))\n",
    "            txt_file = pd.read_csv(data_loc+j+'/labels/'+labels_eko(k), sep=\"\\t\", header = None)\n",
    "            labels = txt_file.iloc[:,2]\n",
    "            start = txt_file.iloc[:,0]\n",
    "            stop = txt_file.iloc[:,1]\n",
    "            for l,m in enumerate(labels):\n",
    "                if m.find('nnotat') != -1:\n",
    "                    sub_wav_mfcc_eko.append(MFCC(waveform_eko[:,int(round(start[l]*sample_rate)):int(round(stop[l]*sample_rate))], sample_rate).numpy().tolist())\n",
    "                    sub_wav_mfcc_mic.append(MFCC(waveform_mic[:,int(round(start[l]*sample_rate_2)):int(round(stop[l]*sample_rate_2))], sample_rate_2).numpy().tolist())\n",
    "            eko.append(sub_wav_mfcc_eko)\n",
    "            mic.append(sub_wav_mfcc_mic)\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        A['eko']= eko\n",
    "        A['mic']= mic\n",
    "        with open(\"./144_MFCC_calculated/\"+j+\".json\", \"w\") as outfile:  \n",
    "            json.dump(A, outfile)\n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "#     for k in os.listdir(data_loc+j+'/Mic'):\n",
    "#             sub_wav_mfcc = []\n",
    "#             waveform_mic, sample_rate = torchaudio.load(data_loc+j+'/Mic/'+k)\n",
    "#             txt_file = pd.read_csv(data_loc+j+'/labels/'+labels_eko(k), sep=\"\\t\", header = None)\n",
    "#             labels = txt_file.iloc[:,2]\n",
    "#             start = txt_file.iloc[:,0]\n",
    "#             stop = txt_file.iloc[:,1]\n",
    "#             for l,m in enumerate(labels):\n",
    "#                 if m.find('nnotat') != -1:\n",
    "#                     sub_wav_mfcc.append(MFCC(waveform_mic[:,int(round(start[l]*sample_rate)):int(round(stop[l]*sample_rate))], sample_rate).numpy().tolist())\n",
    "#             mic.append(sub_wav_mfcc)\n",
    "#         A['mic']= mic\n",
    "#         with open(\"./MFCC_calculated/\"+j+\".json\", \"w\") as outfile:  \n",
    "#             json.dump(A, outfile)\n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

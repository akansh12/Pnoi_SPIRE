{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akansh/anaconda3/lib/python3.7/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  '\"sox\" backend is being deprecated. '\n"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json  \n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_eko_to_mic (wav_file_name):\n",
    "    b = k.split('_')\n",
    "    b[1] = 'Mic'\n",
    "    separator = '_'\n",
    "    return separator.join(b)[:-3] +'wav'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MFCC(waveform, sample_rate):\n",
    "    mfcc = torchaudio.compliance.kaldi.mfcc(waveform=waveform,num_ceps = 12,   \n",
    "                                     cepstral_lifter=22, channel=0, \n",
    "                                     dither = 0.0, energy_floor=0.0,\n",
    "                                     frame_length=20, frame_shift=10, \n",
    "                                     high_freq=sample_rate/2,low_freq = 40, num_mel_bins=25, \n",
    "                                     sample_frequency=sample_rate, use_energy=True, vtln_low =60  , vtln_high = 7200, \n",
    "                                     window_type=\"hamming\")\n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_eko (wav_file_name):\n",
    "    k = wav_file_name\n",
    "    b = k.split('_')\n",
    "    b[1] = 'Label'\n",
    "    separator = '_'\n",
    "    return separator.join(b)[:-3] +'txt'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]/home/akansh/anaconda3/lib/python3.7/site-packages/torchaudio/compliance/kaldi.py:574: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n",
      "  fft = torch.rfft(strided_input, 1, normalized=False, onesided=True)\n",
      "100%|██████████| 7/7 [01:23<00:00, 12.04s/it]\n",
      "100%|██████████| 8/8 [01:31<00:00, 11.20s/it]\n",
      "100%|██████████| 7/7 [01:10<00:00,  9.76s/it]\n",
      "100%|██████████| 8/8 [01:21<00:00,  9.67s/it]\n",
      "100%|██████████| 8/8 [01:12<00:00,  9.00s/it]\n",
      "100%|██████████| 8/8 [01:18<00:00, 10.00s/it]\n",
      "100%|██████████| 7/7 [01:03<00:00,  9.12s/it]\n"
     ]
    }
   ],
   "source": [
    "set_loc = \"./Sets/\"\n",
    "data_loc = \"./\"\n",
    "new_sample_rate = 16000\n",
    "channel = 0\n",
    "for i in os.listdir(set_loc):\n",
    "    set_full = np.loadtxt(set_loc + i, dtype=str)\n",
    "    for j in tqdm(set_full):\n",
    "        A = {}\n",
    "        eko = {}\n",
    "        mic = {}\n",
    "#         eko = []\n",
    "#         mic = []\n",
    "        B_R_T_DPB = []\n",
    "        B_R_D_DPB = []\n",
    "        B_L_D_DPB = []\n",
    "        B_L_T_DPB = []\n",
    "        for k in os.listdir(data_loc+j+'/Eko'):\n",
    "            sub_wav_mfcc = []\n",
    "            waveform_eko, sample_rate = torchaudio.load(data_loc+j+'/Eko/'+k)\n",
    "            txt_file = pd.read_csv(data_loc+j+'/labels/'+labels_eko(k), sep=\"\\t\", header = None)\n",
    "            labels = txt_file.iloc[:,2]\n",
    "            start = txt_file.iloc[:,0]\n",
    "            stop = txt_file.iloc[:,1]\n",
    "            for l,m in enumerate(labels):\n",
    "                if m.find('nnotat') != -1:\n",
    "                    sub_wav_mfcc.append(MFCC(waveform_eko[:,int(round(start[l]*sample_rate)):int(round(stop[l]*sample_rate))], sample_rate).numpy().tolist())\n",
    "            if k.find('B_R_T_DPB') != -1:\n",
    "                B_R_T_DPB.append(sub_wav_mfcc)\n",
    "            if k.find('B_R_D_DPB') != -1:\n",
    "                B_R_D_DPB.append(sub_wav_mfcc)\n",
    "            if k.find('B_L_D_DPB') != -1:\n",
    "                B_L_D_DPB.append(sub_wav_mfcc)\n",
    "            if k.find('B_L_T_DPB') != -1:\n",
    "                B_L_T_DPB.append(sub_wav_mfcc)\n",
    "        eko['B_R_T_DPB'] = B_R_T_DPB\n",
    "        eko['B_R_D_DPB'] = B_R_D_DPB\n",
    "        eko['B_L_D_DPB'] = B_L_D_DPB\n",
    "        eko['B_L_T_DPB'] = B_L_T_DPB\n",
    "        A['eko']= eko\n",
    "        B_R_T_DPB = []\n",
    "        B_R_D_DPB = []\n",
    "        B_L_D_DPB = []\n",
    "        B_L_T_DPB = []\n",
    "        for k in os.listdir(data_loc+j+'/Mic'):\n",
    "            sub_wav_mfcc = []\n",
    "            waveform_mic, sample_rate = torchaudio.load(data_loc+j+'/Mic/'+k)\n",
    "            transformed = torchaudio.transforms.Resample(sample_rate, new_sample_rate)(waveform_mic[channel,:].view(1,-1))\n",
    "            txt_file = pd.read_csv(data_loc+j+'/labels/'+labels_eko(k), sep=\"\\t\", header = None)\n",
    "            labels = txt_file.iloc[:,2]\n",
    "            start = txt_file.iloc[:,0]\n",
    "            stop = txt_file.iloc[:,1]\n",
    "            for l,m in enumerate(labels):\n",
    "                if m.find('nnotat') != -1:\n",
    "                    sub_wav_mfcc.append(MFCC(transformed[:,int(round(start[l]*new_sample_rate)):int(round(stop[l]*new_sample_rate))], new_sample_rate).numpy().tolist())\n",
    "            if k.find('B_R_T_DPB') != -1:\n",
    "                B_R_T_DPB.append(sub_wav_mfcc)\n",
    "            if k.find('B_R_D_DPB') != -1:\n",
    "                B_R_D_DPB.append(sub_wav_mfcc)\n",
    "            if k.find('B_L_D_DPB') != -1:\n",
    "                B_L_D_DPB.append(sub_wav_mfcc)\n",
    "            if k.find('B_L_T_DPB') != -1:\n",
    "                B_L_T_DPB.append(sub_wav_mfcc)        \n",
    "        mic['B_R_T_DPB'] = B_R_T_DPB\n",
    "        mic['B_R_D_DPB'] = B_R_D_DPB\n",
    "        mic['B_L_D_DPB'] = B_L_D_DPB\n",
    "        mic['B_L_T_DPB'] = B_L_T_DPB\n",
    "        A['mic']= mic\n",
    "        with open(\"./\"+j+\".json\", \"w\") as outfile:  \n",
    "            json.dump(A, outfile)\n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform_mic, sample_rate = torchaudio.load(\"./Anita_Mic_2019_11_06_12_53_28.270_B_R_T_DPB_1.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.506530612244894"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveform_mic.shape[1]/sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = 0\n",
    "new_sample_rate = 16000\n",
    "transformed = torchaudio.transforms.Resample(sample_rate, new_sample_rate)(waveform_mic[channel,:].view(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0133, -0.0113, -0.0119,  ..., -0.0014, -0.0010, -0.0017])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 144 MFCC(concat eko and Mic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:44<00:00,  6.60s/it]\n",
      "100%|██████████| 8/8 [01:01<00:00,  8.05s/it]\n",
      "100%|██████████| 7/7 [00:46<00:00,  6.94s/it]\n",
      "100%|██████████| 8/8 [00:52<00:00,  6.35s/it]\n",
      "100%|██████████| 8/8 [00:45<00:00,  5.55s/it]\n",
      "100%|██████████| 8/8 [00:44<00:00,  5.54s/it]\n",
      "100%|██████████| 7/7 [00:38<00:00,  5.68s/it]\n"
     ]
    }
   ],
   "source": [
    "set_loc = \"./Sets/\"\n",
    "data_loc = \"./\"\n",
    "for i in os.listdir(set_loc):\n",
    "    set_full = np.loadtxt(set_loc + i, dtype=str)\n",
    "    for j in tqdm(set_full):\n",
    "        A = {}\n",
    "        eko = []\n",
    "        mic = []   \n",
    "        for k in os.listdir(data_loc+j+'/Eko'):\n",
    "            sub_wav_mfcc_eko = []\n",
    "            sub_wav_mfcc_mic = []\n",
    "            waveform_eko, sample_rate = torchaudio.load(data_loc+j+'/Eko/'+k)\n",
    "            waveform_mic, sample_rate_2 = torchaudio.load(data_loc+j+'/Mic/'+labels_eko_to_mic(k))\n",
    "            txt_file = pd.read_csv(data_loc+j+'/labels/'+labels_eko(k), sep=\"\\t\", header = None)\n",
    "            labels = txt_file.iloc[:,2]\n",
    "            start = txt_file.iloc[:,0]\n",
    "            stop = txt_file.iloc[:,1]\n",
    "            for l,m in enumerate(labels):\n",
    "                if m.find('nnotat') != -1:\n",
    "                    sub_wav_mfcc_eko.append(MFCC(waveform_eko[:,int(round(start[l]*sample_rate)):int(round(stop[l]*sample_rate))], sample_rate).numpy().tolist())\n",
    "                    sub_wav_mfcc_mic.append(MFCC(waveform_mic[:,int(round(start[l]*sample_rate_2)):int(round(stop[l]*sample_rate_2))], sample_rate_2).numpy().tolist())\n",
    "            eko.append(sub_wav_mfcc_eko)\n",
    "            mic.append(sub_wav_mfcc_mic)\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        A['eko']= eko\n",
    "        A['mic']= mic\n",
    "        with open(\"./144_MFCC_calculated/\"+j+\".json\", \"w\") as outfile:  \n",
    "            json.dump(A, outfile)\n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "#     for k in os.listdir(data_loc+j+'/Mic'):\n",
    "#             sub_wav_mfcc = []\n",
    "#             waveform_mic, sample_rate = torchaudio.load(data_loc+j+'/Mic/'+k)\n",
    "#             txt_file = pd.read_csv(data_loc+j+'/labels/'+labels_eko(k), sep=\"\\t\", header = None)\n",
    "#             labels = txt_file.iloc[:,2]\n",
    "#             start = txt_file.iloc[:,0]\n",
    "#             stop = txt_file.iloc[:,1]\n",
    "#             for l,m in enumerate(labels):\n",
    "#                 if m.find('nnotat') != -1:\n",
    "#                     sub_wav_mfcc.append(MFCC(waveform_mic[:,int(round(start[l]*sample_rate)):int(round(stop[l]*sample_rate))], sample_rate).numpy().tolist())\n",
    "#             mic.append(sub_wav_mfcc)\n",
    "#         A['mic']= mic\n",
    "#         with open(\"./MFCC_calculated/\"+j+\".json\", \"w\") as outfile:  \n",
    "#             json.dump(A, outfile)\n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MFCC Calculate for Aug_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_loc = \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_mic(wav_file_name):\n",
    "    if wav_file_name[0] == 'r':\n",
    "        return labels_eko(wav_file_name)[6:]\n",
    "    if wav_file_name[0] == 'u':\n",
    "        return labels_eko(wav_file_name[21:])\n",
    "    if wav_file_name[0] == 'b':\n",
    "        return labels_eko(wav_file_name[12:])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:39<00:00,  6.04s/it]\n",
      "100%|██████████| 8/8 [00:47<00:00,  5.78s/it]\n",
      "100%|██████████| 7/7 [00:39<00:00,  5.66s/it]\n",
      "100%|██████████| 8/8 [00:44<00:00,  5.41s/it]\n",
      "100%|██████████| 8/8 [00:41<00:00,  5.26s/it]\n",
      "100%|██████████| 8/8 [00:45<00:00,  5.65s/it]\n",
      "100%|██████████| 7/7 [00:42<00:00,  6.85s/it]\n"
     ]
    }
   ],
   "source": [
    "set_loc = \"./Sets/\"\n",
    "data_loc = \"./Augmented_Data/Aug\"\n",
    "label_loc = \"./\"\n",
    "new_sample_rate = 16000\n",
    "channel = 0\n",
    "for i in os.listdir(set_loc):\n",
    "    set_full = np.loadtxt(set_loc + i, dtype=str)\n",
    "    for j in tqdm(set_full):\n",
    "        A = {}\n",
    "        eko = {}\n",
    "        mic = {}\n",
    "        B_R_T_DPB = []\n",
    "        B_R_D_DPB = []\n",
    "        B_L_D_DPB = []\n",
    "        B_L_T_DPB = []\n",
    "        for k in os.listdir(data_loc+j+'/Eko'):\n",
    "            sub_wav_mfcc = []\n",
    "            waveform_eko, sample_rate = torchaudio.load(data_loc+j+'/Eko/'+k)\n",
    "            txt_file = pd.read_csv(label_loc+j+'/labels/'+labels_eko(k)[6:], sep=\"\\t\", header = None)\n",
    "            labels = txt_file.iloc[:,2]\n",
    "            start = txt_file.iloc[:,0]\n",
    "            stop = txt_file.iloc[:,1]\n",
    "            for l,m in enumerate(labels):\n",
    "                if m.find('nnotat') != -1:\n",
    "                    sub_wav_mfcc.append(MFCC(waveform_eko[:,int(round(start[l]*sample_rate)):int(round(stop[l]*sample_rate))], sample_rate).numpy().tolist())\n",
    "            if k.find('B_R_T_DPB') != -1:\n",
    "                B_R_T_DPB.append(sub_wav_mfcc)\n",
    "            if k.find('B_R_D_DPB') != -1:\n",
    "                B_R_D_DPB.append(sub_wav_mfcc)\n",
    "            if k.find('B_L_D_DPB') != -1:\n",
    "                B_L_D_DPB.append(sub_wav_mfcc)\n",
    "            if k.find('B_L_T_DPB') != -1:\n",
    "                B_L_T_DPB.append(sub_wav_mfcc)\n",
    "        eko['B_R_T_DPB'] = B_R_T_DPB\n",
    "        eko['B_R_D_DPB'] = B_R_D_DPB\n",
    "        eko['B_L_D_DPB'] = B_L_D_DPB\n",
    "        eko['B_L_T_DPB'] = B_L_T_DPB\n",
    "        A['eko']= eko\n",
    "        B_R_T_DPB = []\n",
    "        B_R_D_DPB = []\n",
    "        B_L_D_DPB = []\n",
    "        B_L_T_DPB = []\n",
    "        for k in os.listdir(data_loc+j+'/Mic'):\n",
    "            sub_wav_mfcc = []\n",
    "            waveform_mic, sample_rate = torchaudio.load(data_loc+j+'/Mic/'+k)\n",
    "            transformed = torchaudio.transforms.Resample(sample_rate, new_sample_rate)(waveform_mic[channel,:].view(1,-1))\n",
    "            txt_file = pd.read_csv(label_loc+j+'/labels/'+labels_mic(k), sep=\"\\t\", header = None)\n",
    "            labels = txt_file.iloc[:,2]\n",
    "            start = txt_file.iloc[:,0]\n",
    "            stop = txt_file.iloc[:,1]\n",
    "            for l,m in enumerate(labels):\n",
    "                if m.find('nnotat') != -1:\n",
    "                    sub_wav_mfcc.append(MFCC(transformed[:,int(round(start[l]*new_sample_rate)):int(round(stop[l]*new_sample_rate))], new_sample_rate).numpy().tolist())\n",
    "            if k.find('B_R_T_DPB') != -1:\n",
    "                B_R_T_DPB.append(sub_wav_mfcc)\n",
    "            if k.find('B_R_D_DPB') != -1:\n",
    "                B_R_D_DPB.append(sub_wav_mfcc)\n",
    "            if k.find('B_L_D_DPB') != -1:\n",
    "                B_L_D_DPB.append(sub_wav_mfcc)\n",
    "            if k.find('B_L_T_DPB') != -1:\n",
    "                B_L_T_DPB.append(sub_wav_mfcc)        \n",
    "        mic['B_R_T_DPB'] = B_R_T_DPB\n",
    "        mic['B_R_D_DPB'] = B_R_D_DPB\n",
    "        mic['B_L_D_DPB'] = B_L_D_DPB\n",
    "        mic['B_L_T_DPB'] = B_L_T_DPB\n",
    "        A['mic']= mic\n",
    "        with open(\"./\"+'Aug'+j+\".json\", \"w\") as outfile:  \n",
    "            json.dump(A, outfile)\n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
